# Beagle Burnout Brigade
## Team Members:
  - Adam Atbi
  - Daven Chohan
  - Hong Quang Cung

![Team_Image](https://github.com/cungquang/CMPT433_FinalProject/blob/main/2024_04_12%4012_00_02-0809.jpg)

## Project Description

The project aims to develop a robotic car utilizing a camera to detect human faces, calculate
their position, and autonomously navigate towards them, stopping precisely at their feet with the
aid of an ultrasonic sensor. The Beagle Bone will communicate with a Python server for image
analysis in order to accurately identify the target in the image.

### Accomplishments:
 - The robotic car is capable of detecting humans in images.
 - It can autonomously rotate to search for humans.
 - Equipped with a camera, the robotic car captures the current scene and transmits images to the server.
 - The Python server (TCP) receives images from the robotic car, detects humans, and returns the distance between them and the center of the picture if present.
 - Ultrasound is able to measure the distance between human and the robotic car in cm
 - Robotic car can be manually turned off by using joystick
 - Buzzer plays an audio cue whenever it transmits an TCP message to the server
 - 14-Seg display was able to accurately acquire how many pictures have been taken and display it

### Video Demo:

[Link_To_Project_Demo_Video](https://www.youtube.com/watch?v=vF6NraIldHc)

## General Server File Sturcture (Code)

- `ai_server/`: Contains all AI and TCP Server code
- `hal/`: Contains all low-level hardware abstraction layer (HAL) modules
- `app/`: Contains all application-specific code. Broken into modules and a main file
- `build/`: Generated by CMake; stores all temporary build files (may be deleted to clean)

```
  .
  ├── ai_server
  │   ├── human_detection_server.py
  │   ├── human_detection_test.py
  │   └── test_image.jpg
  ├── app
  │   ├── include
  │   │   └── <file_name>.h
  │   ├── src
  │   │   ├── <file_name>.c
  │   │   └── main.c
  │   └── CMakeLists.txt           # Sub CMake file, just for app/
  ├── hal
  │   ├── include
  │   │   └── hal
  │   │       └── <hardware_filename>.h
  │   ├── src
  │   │   └── <hardware_filename>.c
  │   └── CMakeLists.txt           # Sub CMake file, just for hal/
  ├── CMakeLists.txt               # Main CMake file for the project
  └── README.md
```  

## Usage

### Setup for Visual Studio Code
- Install CMake: `sudo apt update` and `sudo apt install cmake`
- When you first open the project, click the "Build" button in the status bar for CMake to generate the `build\` folder and recreate the makefiles.
  - When you edit and save a CMakeLists.txt file, VS Code will automatically update this folder.
- When you add a new file (.h or .c) to the project, you'll need to rerun CMake's build
  (Either click "Build" or resave `/CMakeLists.txt` to trigger VS Code re-running CMake)
- Cross-compile using VS Code's CMake addon:
  - The "kit" defines which compilers and tools will be run.
  - Change the kit via the menu: Help > Show All Commands, type "CMake: Select a kit".
    - Kit "GCC 10.2.1 arm-linux-gnueabi" builds for target.
    - Kit "Unspecified" builds for host (using default `gcc`).
  - Most CMake options for the project can be found in VS Code's CMake view (very left-hand side).
- Build the project using Ctrl+Shift+B, or by the menu: Terminal > Run Build Task...
  - If you try to build but get an error about "build is not a directory", the re-run CMake's build as mentioned above.

### Setup for Camera
#### Step 1: Install these libraries on both the host (Linux Debian 11) and target (Beagle Bone)
- They are required on the host for the IDE to not complain which can make coding easier
- They are required on the target to be utilized by the Beaglebone
```
sudo apt-get install libv4l-dev
sudo apt-get install v4l-utils
```

#### Step 2: Move library files to a shared location
- Have a shared folder between the target and the host (via NFS). Here is the NFS guide: https://opencoursehub.cs.sfu.ca/bfraser/grav-cms/cmpt433/guides/files/NFSGuide.pdf
- Copy the following files to the shared folder (located in /usr/lib/arm-linux-gnueabihf)
```
libv4lconvert.so
libjpeg.so
libv4l2.so
```

#### Step 3: Copy picture taking code
- Clone the grabber.c file (credit to Derek Molloy) `https://github.com/derekmolloy/boneCV/blob/master/grabber.c`
- Add the code to an existing file or make grabber.c an executable using cmake
- In CMakeLists.txt file and make sure you link the libraries you copied in Step 2.
```
target_link_libraries(hal PRIVATE
${Home}/Project/public/public/pkgs/libv4l2.so
${Home}/Project/public/public/pkgs/libv4lconvert.so
${Home}/Project/public/public/pkgs/libjpeg.so
```

#### Step 4: Connect USB Camera
- Plug in your USB camera to the Beaglebone
- Ensure the Beaglebone recognizes the camera by running lsusb

#### Step 5: Run your executable
- Your Beaglebone needs write permissions to create the image file and save it
- The image is saved wherever your executable was run from
- The image is saved as a .ppm file

### Setup for Python Server
 #### Step 1: Setup AWS Rekognition
 
  - Register an AWS account (select region: ‘us-east-1’, or choose your region)
  - Setup IAM Policy:
    - Open AWS Console
    - In “IAM”, select “Users” (left side panel)
    - Click on “Create User” to create new user
    - Provide name for “User”
    - You might need to grant “programmatic access” - follow the link: https://docs.aws.amazon.com/rekognition/latest/dg/sdk-programmatic-access.html#programmatic-access-general	
    - In the “Permission Options”, for simplicity, select “Attach policies directly”
    - In “Attach policies directly” select “AmazonRekognitionFullAccess”, then create
  - Setup Access key:
    - Open the “User” is created in the above section
    - Click on “Create access key”
    - Under “Access key best practices & alternatives”, select “Application running outside AWS”
    - Click “Create access key” to complete the process
    - Save the “Access key” and “Secret access key” - later use to access AWS Rekognition

#### Step 2: Install Dependencies on Host (Linux - debian 11)
  - Install python and pip on host machine using below command
```
(host) ~$ sudo apt update
(host) ~$ sudo apt install python3
(host) ~$ sudo apt install python3-pip
```
  - Install boto3 package
```
(host) ~$ sudo pip3 install boto3
```

#### Step 3: Setup Python Server - TCP Protocol

 - Libraries requires: “boto3”, “os”
 - Use “os” library to get environment variable at run-time
 - Provide “Access key” and “Secret Key” at run-time (AWS & Git does not allow you to expose these information publicly)
```
Example:
AWS_Access_key:fake_access_key AWS_Secret_Key:fake_secret_key python3 humandetection.py
``` 

 - In server code, include this snippet to run AWS Rekognition:
```
AWS_ID = os.environ.get('AWS_ID')
AWS_ACCESS = os.environ.get('AWS_ACCESS')
client = boto3.client('rekognition', 
        aws_access_key_id=AWS_ACCESS_KEY,
        aws_secret_access_key=AWS_SECRET_ACCESS,
        region_name='us-east-1')
```
#### Step 4: Recommend workflow for TCP Communication (Client in C & Server in Python)

- Server (Python)
    - Establish a server (in Python) to listen for incoming connections - set limit number of connection as you need
    - Create a separate thread to handle the request concurrently
    - Initially, receive the metadata of the image/video, including the file type and size
    - Confirm with the client before proceeding with data processing
    - Receive all data pertaining to the file from the client 
    - Reconstruct the file, store in local storage then send confirmation
    - Call APIs to detect human then send the results
    - Join the thread after connection closure
- Client (C):
    - Send the metadata, two most important things: file type (for reconstruct the file) and file size (expect how many bytes to receive)
    - Wait for server to response before transmitting actual data
    - Segment the image/video data into chunks of data, typically 1024 bytes each
    - Wait for confirmation of successful receiving data 
    - Listening to server’s response for the result of human detection
    - Close connection
 
## Manually Running CMake

To manually run CMake from the command line use:

```shell
  # Regenerate build/ folder and makefiles:
  rm -rf build/         # Wipes temporary build folder
  cmake -S . -B build   # Generate makefiles in build\

  # Build (compile & link) the project
  cmake --build build
```
